# Progetto_EmanueleAnnaGianmarco

## ğŸ‘©â€ğŸ’» Autore

Anna Firinu, Emanuele Anzellotti, Gianmarco Sorrentino

## ğŸ§ Progetto

**The AI DJ â€“ Sistema di Raccomandazione Musicale Interattivo**

---

## ğŸ“Œ Descrizione generale

Questo progetto simula il funzionamento di un sistema di raccomandazione musicale simile a Spotify, basato su un ciclo di **Active Learning**.
Il sistema parte senza alcuna conoscenza dei gusti dellâ€™utente e apprende progressivamente attraverso lâ€™interazione diretta.

# Pulizia dei Dati (Gianmarco Sorrentino, Anna Firinu, Emanuele Anzellotti) e Analisi Esplorativa (Anna Firinu)

## 1. Introduzione

Questa sezione descrive il processo di **pulizia del dataset**, **analisi esplorativa dei dati (EDA)** e **feature engineering** svolto come fase preliminare alla costruzione di un **sistema di raccomandazione musicale basato sul contenuto**, con particolare attenzione al problema del **cold start**.

Lâ€™obiettivo Ã¨ ottenere un dataset:

- pulito e coerente,
- interpretabile dal punto di vista musicale,
- adatto al calcolo di similaritÃ  tra brani.

---

## 2. Caricamento del Dataset e Ispezione Iniziale

Il dataset Ã¨ stato caricato utilizzando la libreria `pandas` ed Ã¨ stato inizialmente analizzato tramite:

- `head()` per una prima ispezione dei dati,
- `info()` per verificare i tipi di dato e la presenza di valori mancanti,
- `describe()` per analizzare le statistiche descrittive,
- conteggio dei valori mancanti e dei duplicati.

Questa fase ha permesso di comprendere la struttura generale del dataset e di individuare eventuali criticitÃ .

---

## 3. Pulizia dei Dati

### 3.1 Gestione dei Valori Mancanti

I valori mancanti sono stati rimossi utilizzando il metodo `dropna()`.  
Questa scelta Ã¨ stata ritenuta appropriata data la dimensione del dataset e la necessitÃ  di lavorare con feature complete per il calcolo delle similaritÃ .

### 3.2 Gestione dei Duplicati

Per evitare la presenza di piÃ¹ istanze della stessa canzone, il dataset Ã¨ stato aggregato utilizzando:

- `track_name`,
- `artists`,
- `album_name`.

Le feature numeriche sono state aggregate tramite media, mentre le feature categoriali sono state mantenute selezionando il primo valore disponibile.  
Questo garantisce una rappresentazione unica e coerente di ciascun brano.

---

## 4. Analisi dei Generi Musicali

### 4.1 Distribuzione dei Generi

Ãˆ stata analizzata la distribuzione della variabile `track_genre` per individuare eventuali sbilanciamenti nel dataset.

### 4.2 Mappatura dei Generi

Per ridurre la dimensionalitÃ  e migliorare la robustezza nella fase di cold start, i generi originali sono stati mappati in un insieme ridotto di **macro-generi** (`main_genre`).  
Il genere originale Ã¨ stato comunque mantenuto come `sub_genre`.

Questa scelta consente:

- raccomandazioni iniziali piÃ¹ stabili,
- una maggiore granularitÃ  quando si accumula feedback dellâ€™utente.

---

## 5. Analisi delle Audio Feature

Le principali audio feature (ad esempio `energy`, `danceability`, `valence`, `acousticness`, ecc.) sono state analizzate tramite istogrammi al fine di studiarne:

- la distribuzione dei valori,
- eventuali asimmetrie,
- la presenza di valori estremi o concentrati.

Lâ€™analisi ha evidenziato che le feature catturano aspetti musicali differenti e non risultano ridondanti.

---

## 6. Analisi di Correlazione

Ãˆ stata calcolata una matrice di correlazione tra le audio feature per analizzare le relazioni lineari tra le variabili.

I risultati mostrano:

- una forte correlazione positiva tra `energy` e `loudness`,
- una forte correlazione negativa tra `energy` e `acousticness`,
- una correlazione moderata tra `danceability` e `valence`,
- feature debolmente correlate come `instrumentalness`, `speechiness` e `tempo`.

Nessuna coppia di feature presenta una correlazione perfetta, rendendo il set di feature adatto a un sistema di raccomandazione basato sul contenuto.

---

## 7. Grafici di Supporto alla Correlazione

Per confermare visivamente i risultati della matrice di correlazione oltre agli scatter plot sono stati utilizzati grafici aggregati piÃ¹ leggibili, tra cui:

- barplot delle medie,
- boxplot,
- istogrammi condizionati.

Questi grafici hanno permesso di:

- confermare le relazioni positive o negative tra le feature,
- evidenziare lâ€™assenza di pattern significativi (ad esempio tra `duration_ms` ed `energy`),
- giustificare lâ€™esclusione di alcune feature dal modello di raccomandazione.

---

## 8. Feature Engineering

Sono state introdotte alcune **feature derivate** per rappresentare concetti musicali di livello piÃ¹ alto:

- `mood_score`: media di `energy` e `valence`, rappresenta il mood complessivo del brano.
- `dance_mood`: combinazione di `danceability` e `valence`.
- `electronic_index`: differenza tra `energy` e `acousticness`, utile per distinguere brani elettronici da brani acustici.
- `is_instrumental`: variabile binaria che identifica i brani strumentali.

Per le feature concettualmente piÃ¹ rilevanti sono stati utilizzati grafici descrittivi per verificarne la distribuzione e lâ€™interpretabilitÃ  musicale.

---

## 9. Selezione Finale delle Feature

Sulla base dellâ€™analisi esplorativa e dello studio delle correlazioni, Ã¨ stato definito un set finale di feature composto da:

- audio feature originali non ridondanti,
- un numero limitato di feature ingegnerizzate.

La feature `duration_ms` Ã¨ stata esclusa in quanto non mostra relazioni significative con gli altri attributi musicali.

---

## 10. Scaling delle Feature

Come ultimo passo della fase di preparazione dei dati, Ã¨ stato applicato uno **scaling Min-Max** per riportare tutte le feature selezionate nellâ€™intervallo \([0,1]\).

Questo passaggio Ã¨ fondamentale per:

- rendere le feature confrontabili,
- evitare che differenze di scala influenzino il calcolo della similaritÃ ,
- preparare i dati allâ€™uso in un sistema di raccomandazione basato sulla similaritÃ  del contenuto.

---

## 11. Conclusione

La fase di pulizia, analisi ed esplorazione ha prodotto un dataset:

- pulito e coerente,
- interpretabile dal punto di vista musicale,
- privo di forte multicollinearitÃ ,
- adatto alla costruzione di un sistema di raccomandazione musicale.

# ğŸ“˜ Architettura del software (Fase A & Fase B & Fase C & Fase D)

## ğŸ…°ï¸ Fase A â€“ Cold Start (Avvio a Freddo) (Firinu Anna)

### ğŸ¯ Obiettivo

Gestire lâ€™avvio del sistema quando il modello non ha ancora informazioni sui gusti dellâ€™utente, raccogliendo le prime etichette necessarie per il training iniziale.

---

### âš™ï¸ FunzionalitÃ  implementate

- Caricamento del dataset musicale da file CSV
- Pulizia **temporanea e minimale** dei dati (rimozione valori nulli nelle feature numeriche),  
  effettuata **in attesa dellâ€™integrazione del modulo dedicato al preprocessing dei dati**
- Estrazione casuale di **N canzoni** dal dataset
- Visualizzazione di:
  - Titolo
  - Artista
  - Genere
- Raccolta del voto dellâ€™utente:
  - `1` â†’ Mi piace
  - `0` â†’ Non mi piace
- Creazione dello storico utente (`user_history`)
- Tracciamento delle canzoni giÃ  ascoltate (`seen_tracks`) per evitare ripetizioni

---

### ğŸ“Š Output della Fase A

- `user_history` â†’ DataFrame contenente:
  - Feature audio numeriche
  - Voto dellâ€™utente
  - Metadati (titolo, artista)
- `seen_tracks` â†’ insieme di `track_id` giÃ  valutati

Questi output costituiscono il **dataset di training iniziale** per le fasi successive del progetto.

---

### ğŸ“ File coinvolti

- `faseA.py`

---

# Fasi B e C (Emanuele Anzellotti)

## Obiettivo

Le fasi B e C del progetto hanno lâ€™obiettivo di creare un modello di classificazione binaria che impari dai feedback dellâ€™utente e predica la probabilitÃ  che un brano venga apprezzato:

$$P(\text{â€œmi piaceâ€}=1 \mid \text{feature audio})$$

Il sistema Ã¨ progettato per apprendere in tempo reale, aggiornando il modello dopo ogni voto e suggerendo brani con confidenza crescente o, alternativamente, esplorando quelli piÃ¹ incerti.

## Fase B â€“ Training del modello

1. Input: feedback dellâ€™utente (user_history) con feature audio numeriche e label 0/1.
2. Condizione pre-addestramento: il modello viene costruito solo se ci sono almeno due classi presenti (almeno un like e un dislike).
3. Scelta del modello:
   - Random Forest (RF) -> ideale per dataset piccoli, infatti messo di default.
   - MLP (Multi-Layer Perceptron) -> abilitato dopo 30 voti.
4. Pipeline: tutte le feature vengono scalate con MinMaxScaler per uniformitÃ  tra RF e MLP.
5. Training: ogni volta che arriva un nuovo feedback, il modello viene riaddestrato per incorporare la nuova informazione.
6. Output: pipeline addestrata salvata nello state["model"].

## Fase C â€“ Predizione & Active Learning

1. Input: pool di brani non ancora ascoltati (candidate_df) e modello addestrato.
2. Predizione: il modello calcola la probabilitÃ  di like per ciascun brano.
3. Exploration/Exploitation:
   - Exploitation (70%) -> scegliere la canzone con probabilitÃ  di like piÃ¹ alta.
   - Exploration (30%) -> scegliere la canzone con probabilitÃ  piÃ¹ vicina a 0.5, dove il modello Ã¨ piÃ¹ incerto.
4. Motivazione: proporre brani incerti permette al modello di imparare piÃ¹ velocemente.

### ğŸ“ File coinvolti

- `faseBC.py`

## ğŸ…³ Fase D â€“ Interazione e Feedback Loop (Anna Firinu)

### ğŸ¯ Obiettivo

Gestire lâ€™interazione tra utente e sistema dopo che il modello Ã¨ stato addestrato, chiudendo il ciclo di Active Learning.

---

### âš™ï¸ FunzionalitÃ  implementate

- Visualizzazione della canzone raccomandata dal modello
- Stampa della **probabilitÃ  stimata di gradimento**
- Raccolta del verdetto reale dellâ€™utente (1 / 0)
- Aggiornamento dinamico dello storico utente (`user_history`)
- Aggiornamento delle canzoni giÃ  ascoltate (`seen_tracks`)
- Preparazione dei dati per il ri-addestramento del modello

---

### ğŸ” Feedback Loop

Ogni nuova interazione:

1. Viene salvata nello storico utente
2. Arricchisce il dataset di training
3. Permette al modello di migliorare progressivamente le raccomandazioni

Questo meccanismo realizza un ciclo di **Apprendimento Attivo (Active Learning)**.

---

### ğŸ“ File coinvolti

- `faseD.py`

# ğŸ”š Conclusione e Integrazione del Sistema

Oltre alle singole fasi descritte, una parte fondamentale del progetto ha riguardato
lâ€™**integrazione complessiva del sistema di raccomandazione** e il collegamento tra
la logica applicativa e i dati preprocessati.

In particolare:

- **Anna Firinu** ed **Emanuele Anzellotti** si sono occupati della **creazione del file main**
  e dellâ€™**orchestrazione delle diverse fasi del progetto** (Fase A, B, C e D),
  garantendo un flusso di esecuzione coerente e continuo.

- Il main gestisce:

  - lâ€™avvio del sistema in modalitÃ  cold start,
  - il passaggio progressivo tra raccolta dei feedback, training del modello,
    predizione e interazione con lâ€™utente,
  - la condivisione dello stato tra le varie fasi (storico utente, modello, canzoni viste).

- **Emanuele Anzellotti** si Ã¨ inoltre occupato del **collegamento finale dellâ€™intero sistema
  al dataset pulito, analizzato e preprocessato**, assicurando che:
  - le feature selezionate e ingegnerizzate venissero utilizzate correttamente,
  - lo scaling fosse coerente tra preprocessing ed esecuzione del modello,
  - il sistema di raccomandazione operasse su dati consistenti e affidabili.

Grazie a questa integrazione, il progetto non si limita a una collezione di moduli separati,
ma realizza un **sistema completo, modulare e interattivo**, capace di apprendere
progressivamente dai feedback dellâ€™utente attraverso un ciclo di **Active Learning**.
